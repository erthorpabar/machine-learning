{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "y_pred = 推理函数\n",
    "a = 学习率\n",
    "\n",
    "——————————推理函数y_pred——————————\n",
    "设\n",
    "w = [w0,w1] (权重向量)\n",
    "x = [1,x1] (特征向量 x0 = 1 代表截距)\n",
    "\n",
    "y = wx =  w0*1 + w1*x1\n",
    "\n",
    "推理函数\n",
    "y_pred = y\n",
    "\n",
    "\n",
    "——————————损失函数L——————————\n",
    "y = 标签\n",
    "二次方距离作为损失函数\n",
    "L = (y_pred - y)^2\n",
    "\n",
    "\n",
    "——————————损失函数对于w的偏导数dL——————————\n",
    "令u = (y_pred - y)\n",
    "dL/dw \n",
    "= 2u * u'\n",
    "2u = 2(y_pred - y)\n",
    "u' = (wx - y)' = x\n",
    "\n",
    "则\n",
    "dL/dw = 2(y_pred - y) * x\n",
    "\n",
    "\n",
    "——————————更新权重——————————\n",
    "w = w - a * dL\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   \n",
    "1 梯度下降 \n",
    "所有样本计算 dL/dw 后 更新\n",
    "\n",
    "2 随机梯度下降\n",
    "单个样本计算 dL/dw 后 更新\n",
    "\n",
    "3 正规方程\n",
    "损失函数是一个二次函数 \n",
    "因此最小值在 dL/dw = 0 处\n",
    "\n",
    "2(y_pred - y) * x = 0 \n",
    "2(wx - y) * x = 0 \n",
    "x^2w = xy\n",
    "w = (x^2)^-1 * xy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LinearRegression:\n",
    "    def __init__(self, l_rate=0.01, n_iterations=1000, method=\"GD\"):\n",
    "        self.l_rate = 0.01 # 学习率\n",
    "        self.n_iterations = 1000 # 迭代次数\n",
    "        self.method = \"GD\" # 默认的优化方法\n",
    "        self.w = None # 权重\n",
    "\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        ''' \n",
    "        最左增加一列 1 作为截距项\n",
    "        x = [x1, x2, x3] -> [1, x1, x2, x3]\n",
    "\n",
    "        x.shape = (m,n)\n",
    "        m = 样本数\n",
    "        n = 特征数 (包含增加的偏置项)\n",
    "        '''\n",
    "        x = np.concatenate([np.ones((x.shape[0],1)),x],axis=1)\n",
    "        m, n = x.shape \n",
    "        y = y.reshape(-1,1) # 确保形状为(m,1)\n",
    "\n",
    "\n",
    "        if self.method == 'GD': # 梯度下降 算完了一次性更新权重\n",
    "            self.w = np.zeros((n,1)) # 初始化权重\n",
    "            for i in range(self.n_iterations):\n",
    "                ''' \n",
    "                推理函数 y_pred = wx\n",
    "                损失函数 L = (y_pred - y)^2\n",
    "                损失函数对w的偏导数 dL = 2x(y_pred - y)\n",
    "                更新权重 w = w - l_rate * dL\n",
    "                '''\n",
    "                y_pred = x @ self.w \n",
    "                dL = 2 * x.T @ (y_pred - y) / m # 除以m求均值\n",
    "                self.w = self.w - self.l_rate * dL \n",
    "\n",
    "        elif self.method == 'SGD': # 随机梯度下降 每次都更新权重\n",
    "            self.w = np.zeros((n,1)) # 初始化权重\n",
    "            for i in range(self.n_iterations):\n",
    "                # 随机选择一个样本\n",
    "                id = np.random.randint(m) \n",
    "                xi = x[id:id+1]\n",
    "                yi = y[id:id+1]\n",
    "\n",
    "                ''' \n",
    "                推理函数 y_pred = wx\n",
    "                损失函数 L = (y_pred - y)^2\n",
    "                损失函数对w的偏导数 dL = 2x(y_pred - y)\n",
    "                更新权重 w = w - l_rate * dL\n",
    "                '''\n",
    "                y_pred = xi @ self.w \n",
    "                dL = 2 * xi.T @ (y_pred - yi) \n",
    "                self.w = self.w - self.l_rate * dL \n",
    "\n",
    "        elif self.method == 'NormalEquation': # 正规方程 数据的解析解\n",
    "            self.w = np.linalg.inv(x.T @ x) @ x.T @ y # w = (x^2)^-1 * xy\n",
    "\n",
    "\n",
    "    def predict(self,x):\n",
    "        x = np.concatenate([np.ones((x.shape[0],1)),x],axis=1)\n",
    "        return x @ self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用数据:\n",
      "x: [1 2 3 4 5]\n",
      "y: [ 3  5  7  9 11]\n",
      "数据规律 y = 2x + 1\n",
      "[ 2.98987045  4.99375103  6.99763161  9.0015122  11.00539278]\n",
      "[ 2.98987045  4.99375103  6.99763161  9.0015122  11.00539278]\n",
      "[ 2.98987045  4.99375103  6.99763161  9.0015122  11.00539278]\n"
     ]
    }
   ],
   "source": [
    "# 使用模型\n",
    "\n",
    "# 创建数据集\n",
    "np.random.seed(42)\n",
    "x = np.array([[1], [2], [3], [4], [5]])  # 特征：1维，5个样本\n",
    "y = np.array([3, 5, 7, 9, 11])  # 标签：y = 2*x + 1 加少量噪声\n",
    "\n",
    "print(\"使用数据:\")\n",
    "print(f\"x: {x.flatten()}\")\n",
    "print(f\"y: {y}\")\n",
    "print('数据规律 y = 2x + 1')\n",
    "\n",
    "\n",
    "\n",
    "# 实例化 梯度下降\n",
    "model = LinearRegression(l_rate=0.01, n_iterations=100, method=\"GD\")\n",
    "model.fit(x, y) # 训练\n",
    "y_pred = model.predict(x) # 用训练数据预测\n",
    "print(y_pred.flatten())  # 展平为1维数组\n",
    "\n",
    "\n",
    "# 实例化 随机梯度下降\n",
    "model = LinearRegression(l_rate=0.01, n_iterations=100, method=\"SGD\")\n",
    "model.fit(x, y) # 训练\n",
    "y_pred = model.predict(x) # 用训练数据预测\n",
    "print(y_pred.flatten())  # 展平为1维数组\n",
    "\n",
    "# 实例化 正规方程\n",
    "model = LinearRegression(l_rate=0.01, n_iterations=100, method=\"NormalEquation\")\n",
    "model.fit(x, y) # 训练\n",
    "y_pred = model.predict(x) # 用训练数据预测\n",
    "print(y_pred.flatten())  # 展平为1维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
