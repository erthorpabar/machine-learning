{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "y_pred = 推理函数\n",
    "a = 学习率\n",
    "\n",
    "——————————推理函数y_pred——————————\n",
    "设\n",
    "w = [w0,w1] (权重向量)\n",
    "x = [1,x1] (特征向量 x0 = 1 代表截距)\n",
    "y = wx =  w0*1 + w1*x1\n",
    "\n",
    "p = sigmoid(y) = 1 / (1 + e^(-y))\n",
    "将y(-∞,∞) 映射到0-1之间 表示概率 约等于二分类\n",
    "\n",
    "推理函数\n",
    "y_pred = p\n",
    "\n",
    "\n",
    "——————————损失函数L——————————\n",
    "y = 标签 0或1\n",
    "交叉熵作为损失函数\n",
    "L = y * log(1/y_pred) + (1-y) * log(1/(1-y_pred))\n",
    "\n",
    "\n",
    "——————————损失函数对于w的偏导数dL——————————\n",
    "dL/dw\n",
    "1 L-p 的导数\n",
    "2 p-y 的导数\n",
    "3 y-x 的导数\n",
    "4 L-w 的导数\n",
    "\n",
    "——————————1 L-p 的导数————————————————\n",
    "L = y * log(1/y_pred) + (1-y) * log(1/(1-y_pred))\n",
    "L = y * log(1/p) + (1-y) * log(1/(1-p))\n",
    "= -y * log(p) - (1-y) * log(1-p)\n",
    "\n",
    "左边 = -y * log(p)\n",
    "右边 = (1-y) * log(1-p)\n",
    "\n",
    "左边求导\n",
    "= -y * (1/p)\n",
    "\n",
    "右边求导\n",
    "= (1-y) * (1/1-p) * (-1)\n",
    "\n",
    "合并 = 左边 - 右边\n",
    "= -y * (1/p) - (1-y) * (1/1-p) * (-1)\n",
    "= -y * (1/p) + (1-y) * (1/1-p)\n",
    "= (p-y)  /  (p*(1-p))\n",
    "\n",
    "则\n",
    "dL/dp = (p-y)  /  (p*(1-p))\n",
    "\n",
    "——————————2 p-y 的导数 dp/dy————————————————\n",
    "p = sigmoid(y) = 1 / (1 + e^(-y))\n",
    "dp/dy = p * (1-p) \n",
    "\n",
    "——————————3 y-x 的导数 dy/dw————————————————\n",
    "y = wx\n",
    "dy/dw = x\n",
    "\n",
    "——————————4 L-w 的导数 dL/dw————————————————\n",
    "dL/dw = dL/dp * dp/dy * dy/dw\n",
    "= (p-y)  /  (p*(1-p)) *  p * (1-p) * x\n",
    "= (p-y) * x\n",
    "\n",
    "\n",
    "——————————结论————————————————\n",
    "dL/dw = (p-y) * x\n",
    "\n",
    "——————————更新权重——————————\n",
    "w = w - a * dL\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "sigmoid 求导\n",
    "dp/dy\n",
    "p = sigmoid(y) = 1 / (1 + e^(-y))\n",
    "\n",
    "s(y) = 1 / (1 + e^(-y))\n",
    "1-s(y) = e^(-y) / (1 + e^(-y))\n",
    "\n",
    "\n",
    "令 u = 1+e^(-y)\n",
    "则\n",
    "s(y)' = 1/u\n",
    "s'(y) = (1/u)' * u'\n",
    "\n",
    "分开求导\n",
    "(1/u)' \n",
    "= (u^-1)'\n",
    "= -1 * u^-2 \n",
    "= -1/u^2\n",
    "= -1/(1+e^(-y))^2\n",
    "\n",
    "u'\n",
    "= (1+e^(-y))'\n",
    "= 1' + e^(-y)'\n",
    "= 0 + e^(-y)'\n",
    "=  0 + (-y)' * e^(-y)\n",
    "= -e^(-y)\n",
    "\n",
    "合并\n",
    "s'(y) = (1/u)' * u'\n",
    "= e^(-y)  /  (1+e^(-y))^2\n",
    "\n",
    "观察并化简\n",
    "可分解成\n",
    "a = e^(-y)/(1+e^(-y)) = 1-s(y)\n",
    "b = 1/(1+e^(-y)) = s(y)\n",
    "\n",
    "则\n",
    "s'(y) = a * b\n",
    "s'(y) = (1-s(y)) * s(y)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "e^x 求导\n",
    "\n",
    "y = e^x\n",
    "两边取对数 ln(y) = x\n",
    "两边对x求导 1/y * y' = 1\n",
    "y' = y\n",
    "则\n",
    "(e^x)' = e^x\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, l_rate=0.01, n_iterations=1000):\n",
    "        self.l_rate = l_rate  # 学习率\n",
    "        self.n_iterations = n_iterations  # 迭代次数\n",
    "        self.w = None  # 权重\n",
    "    \n",
    "    # sigmoid\n",
    "    def sigmoid(self, y):\n",
    "        return 1 / (1 + np.exp(-y))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        ''' \n",
    "        最左增加一列 1 作为截距项\n",
    "        x = [x1, x2, x3] -> [1, x1, x2, x3]\n",
    "\n",
    "        x.shape = (m,n)\n",
    "        m = 样本数\n",
    "        n = 特征数 (包含增加的偏置项)\n",
    "        '''\n",
    "        x = np.concatenate([np.ones((x.shape[0],1)),x],axis=1)\n",
    "        m, n = x.shape \n",
    "        y = y.reshape(-1,1) # 确保形状为(m,1)\n",
    "\n",
    "        self.w = np.zeros((n,1)) # 初始化权重\n",
    "        for i in range(self.n_iterations):\n",
    "            ''' \n",
    "            推理函数 y_pred = sigmoid(wx)\n",
    "            损失函数 L = y * log(1/y_pred) + (1-y) * log(1/(1-y_pred))\n",
    "            损失函数对w的偏导数 dL = (y_pred-y) * x\n",
    "            更新权重 w = w - l_rate * dL\n",
    "            '''\n",
    "\n",
    "            y_pred = self.sigmoid(x @ self.w)\n",
    "            dL = x.T @ (y_pred - y) / m # 除以m求均值\n",
    "            self.w = self.w - self.l_rate * dL\n",
    "    \n",
    "    # 预测概率\n",
    "    def predict_prob(self, x, threshold=0.5):\n",
    "        x = np.concatenate([np.ones((x.shape[0],1)),x],axis=1)\n",
    "        p = self.sigmoid(x @ self.w)\n",
    "        return p\n",
    "\n",
    "    # 预测类别\n",
    "    def predict(self, x, threshold=0.5):\n",
    "        p = self.predict_prob(x)\n",
    "        return (p >= threshold).astype(int) # 根据阈值 返回 0 或 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用数据:\n",
      "x1: [1 2 1 3 2 3 4 2 3 4]\n",
      "x2: [2 1 3 2 3 3 2 4 4 4]\n",
      "y: [0 0 0 1 1 1 1 1 1 1]\n",
      "数据规律 x1 + x2 >= 5 → y=1 else y=0\n",
      "[0.18 0.39 0.32 0.9  0.75 0.95 0.98 0.87 0.98 1.  ]\n",
      "[0 0 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 使用模型\n",
    "\n",
    "# 创建二分类数据集\n",
    "# x 2个维度 10个训练数据\n",
    "np.random.seed(42)\n",
    "x = np.array([[1, 2], [2, 1], [1, 3], [3, 2], [2, 3], \n",
    "              [3, 3], [4, 2], [2, 4], [3, 4], [4, 4]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "print(\"使用数据:\")\n",
    "print(\"x1:\", x[:, 0])\n",
    "print(\"x2:\", x[:, 1])\n",
    "print(\"y:\", y)\n",
    "print('数据规律 x1 + x2 >= 5 → y=1 else y=0')\n",
    "\n",
    "# 实例化 梯度下降\n",
    "model = LogisticRegression(l_rate=0.1, n_iterations=1000)\n",
    "model.fit(x, y) # 训练\n",
    "\n",
    "y_pred_prob = model.predict_prob(x) # 预测概率\n",
    "y_pred = model.predict(x) # 预测分类\n",
    "print(f\"{y_pred_prob.flatten().round(2)}\") # 输出 0-1 之间的概率\n",
    "print(f\"{y_pred.flatten()}\") # 输出 0 或 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "对于logisitc回归的补充\n",
    "\n",
    "\n",
    "从熵的角度理解\n",
    "p(A) + p(B) = 1 (二分类事件)\n",
    "\n",
    "信息熵\n",
    "n(A) = -log(1/p(A))\n",
    "n(B) = -log(1/p(B))\n",
    "\n",
    "y = n(A) - n(B) 用来衡量谁更有可能发生\n",
    "n(A) - n(B)  > 0 -> A的信息量更高 A更少见 A概率更小\n",
    "n(A) - n(B)  = 0 -> 相等\n",
    "n(A) - n(B)  < 0 -> B的信息量更低 B更常见 B概率更大\n",
    "\n",
    "y = n(A) - n(B)\n",
    "= (-log(1/p(A))) - (-log(1/p(B)))\n",
    "= log(p(A)) - log(p(B))\n",
    "= log(p(A)/p(B))\n",
    "= log(p(A) / (1 - p(A)))\n",
    "\n",
    "y = log(p/(1-p))\n",
    "e^y = p/(1-p)\n",
    "(1-p)e^y = p\n",
    "e^y - e^y * p = p\n",
    "e^y = p + e^y * p\n",
    "e^y = p(1 + e^y)\n",
    "p = e^y / (1 + e^y)\n",
    "p = 1 / (1 + e^(-y))\n",
    "p = sigmoid(y)\n",
    "p = sigmoid(n(A) - n(B))\n",
    "p = sigmoid(log(p/(1-p)))\n",
    "又因为\n",
    "y = wx \n",
    "所以\n",
    "标准写法\n",
    "p = sigmoid(wx)\n",
    "其他写法\n",
    "log(p / (1 - p)) = wx \n",
    "wx = n(A) - n(B)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
